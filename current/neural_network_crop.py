import numpy as np
import matplotlib.pyplot as plt
#%matplotlib inline
#from __future__ import print_function
import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten

import tensorflow as tf
from keras.datasets import cifar10
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

import glob
import cv2


train_images = map(cv2.imread, sorted(glob.glob("/home/rhys/shaynedlima.github.io/image/*")))
train_images = map(lambda img: cv2.resize(img, dsize=(504, 378), interpolation=cv2.INTER_CUBIC), train_images)
train_labels = []
for i in sorted(glob.glob("/home/rhys/shaynedlima.github.io/labels/*")):
    x = open(i)
    train_labels.append(map(lambda x : float(x) / 8.0, str(x.read()).split(",")))


train_images = np.array(train_images)
train_labels = np.array(train_labels)

test_images = train_images

test_labels = train_labels

from keras.utils import to_categorical



print('Training data shape : ', train_images.shape, train_labels.shape)

print('Testing data shape : ', test_images.shape, test_labels.shape)


# Find the unique numbers from the train labels

print('Total number of outputs : ', 4)


# Find the shape of input images and create the variable input_shape
nRows,nCols,nDims = train_images.shape[1:]

train_data = train_images.reshape(train_images.shape[0], nRows, nCols, nDims)

test_data = test_images.reshape(test_images.shape[0], nRows, nCols, nDims)
input_shape = (nRows, nCols, nDims)

# Change to float datatype
train_data = train_data.astype('float32')
test_data = test_data.astype('float32')
# Scale the data to lie between 0 to 1
train_data /= 255
test_data /= 255


# # Display the change for category label using one-hot encoding
# print('Original label 0 : ', train_labels[0])
# print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[0])


def createModel():
    model = Sequential()
    # The first two layers with 32 filters of window size 3x3
    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))
    model.add(Conv2D(32, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4, activation='relu'))

    return model


from keras.preprocessing.image import ImageDataGenerator

model2 = createModel()

model2.compile(optimizer='rmsprop', loss='mean_absolute_error', metrics=['accuracy'])

batch_size = 256
epochs = 1000

datagen = ImageDataGenerator(
#         zoom_range=0.2, # randomly zoom into images
#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images


# datagen.fit(train_data)

# Fit the model on the batches generated by datagen.flow().
history2 = model2.fit_generator(datagen.flow(train_data, train_labels, batch_size=batch_size),
                              #steps_per_epoch=int(np.ceil(train_data.shape[0] / float(batch_size))),
                              steps_per_epoch=int(1),
                              epochs=epochs,
                              validation_data=(test_data, test_labels),
                              workers=4)



model2.evaluate(test_data, test_labels)

predictions = model2.predict(train_data)

print(predictions)

model = model2.to_json()

with open('model.json', 'w') as json_file:
    json_file.write(model)

model2.save_weights('model.h5')


